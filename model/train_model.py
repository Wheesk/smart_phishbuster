
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report, accuracy_score
import joblib
import os

# â”€â”€â”€ 1) Locate project root, data, and model dirs â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
script_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.abspath(os.path.join(script_dir, os.pardir))
data_dir    = os.path.join(project_root, "data")
model_dir   = os.path.join(project_root, "model")
os.makedirs(model_dir, exist_ok=True)

print(f"â–¶ï¸ Loading data from: {data_dir}")
print(f"â–¶ï¸ Saving model to : {model_dir}")

# â”€â”€â”€ 2) Load the full-feature CSV â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
csv_path = os.path.join(data_dir, "full_feature_dataset.csv")
df = pd.read_csv(csv_path)
print("ğŸ” Shape   :", df.shape)
print("ğŸŸ¢ Legit   :", (df["class"] == 1).sum())
print("ğŸ”´ Phish   :", (df["class"] == -1).sum())
print("â“ Missing :", df.isnull().any().any())

# â”€â”€â”€ 3) Split into X / y â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
X = df.drop(columns=["class"])
y = df["class"]
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# â”€â”€â”€ 4) Scale features â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
scaler = StandardScaler()
X_train_s = scaler.fit_transform(X_train)
X_test_s  = scaler.transform(X_test)

# â”€â”€â”€ 5) Train Random Forest â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
model = RandomForestClassifier(
    n_estimators=100,
    random_state=42,
    class_weight="balanced"
)
model.fit(X_train_s, y_train)
print("âœ”ï¸  Trainedâ€Šâ€” Classes:", model.classes_)

# â”€â”€â”€ 6) Evaluate â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
y_pred = model.predict(X_test_s)
print("ğŸ“Š Accuracy :", accuracy_score(y_test, y_pred))
print("ğŸ“‹ Report   :\n", classification_report(y_test, y_pred))

# â”€â”€â”€ 7) Save model, scaler, and feature names â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
joblib.dump(model,  os.path.join(model_dir, "phishing_model.pkl"))
joblib.dump(scaler, os.path.join(model_dir, "scaler.pkl"))

feat_file = os.path.join(model_dir, "feature_names.txt")
with open(feat_file, "w") as f:
    for col in X.columns:
        f.write(col + "\n")

print("âœ… Model, scaler, and feature names written to:", model_dir)
